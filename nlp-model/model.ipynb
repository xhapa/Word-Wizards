{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/xhapa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/xhapa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.tag import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu.parser import parse_line\n",
    "from conllu import parse_incr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_en = 'If Anaconda (conda) and Jupyter Notebook (Jupyter Lab) are set up the right way the combination of them can become the perfect team, where you are able to easily switch between Deep Learning conda environments.'\n",
    "text_tokens_en = word_tokenize(text_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_es = 'Con los niveles del mar en aumento, la contaminación por plásticos y la sobrexplotación pesquera, el emergente internet de las cosas submarinas ampliará enormemente los conocimientos sobre los mares del mundo'\n",
    "text_tokens_es = word_tokenize(text_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data_file(file, tagtype):\n",
    "    sent_list = []\n",
    "\n",
    "    for token_list in parse_incr(file):\n",
    "        word_list = []\n",
    "        for token in token_list:\n",
    "            word_list.append((token['form'], token[tagtype]))\n",
    "        sent_list.append(word_list)\n",
    "    \n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Según', 'ADP'),\n",
       " ('el', 'DET'),\n",
       " ('informe', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('el', 'DET')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = open('./datasets/UD_Spanish-AnCora/es_ancora-ud-train.conllu', encoding='utf-8')\n",
    "tagtype = 'upos'\n",
    "data = parse_data_file(data_file, tagtype)\n",
    "data[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456698725603004"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_es = hmm.HiddenMarkovModelTagger.train(train_set)\n",
    "predicted_set = tagger_es.tag(text_tokens_es)\n",
    "tagger_es.accuracy(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('If', 'IN'),\n",
       " ('Anaconda', 'NNP'),\n",
       " ('(', '('),\n",
       " ('conda', 'NN'),\n",
       " (')', ')'),\n",
       " ('and', 'CC'),\n",
       " ('Jupyter', 'NNP'),\n",
       " ('Notebook', 'NNP'),\n",
       " ('(', '('),\n",
       " ('Jupyter', 'NNP'),\n",
       " ('Lab', 'NNP'),\n",
       " (')', ')'),\n",
       " ('are', 'VBP'),\n",
       " ('set', 'VBN'),\n",
       " ('up', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('combination', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('become', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('perfect', 'JJ'),\n",
       " ('team', 'NN'),\n",
       " (',', ','),\n",
       " ('where', 'WRB'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('easily', 'RB'),\n",
       " ('switch', 'VB'),\n",
       " ('between', 'IN'),\n",
       " ('Deep', 'NNP'),\n",
       " ('Learning', 'NNP'),\n",
       " ('conda', 'NN'),\n",
       " ('environments', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(text_tokens_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tagger_es model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hmm_tagger_es.dill', 'wb') as f:\n",
    "    dill.dump(tagger_es, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
